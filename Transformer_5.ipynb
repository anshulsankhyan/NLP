{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbwl6E1E205R",
        "outputId": "954b8e01-5686-41c0-aa25-29131803c467"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install rich[jupyter]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rich[jupyter] in /usr/local/lib/python3.10/dist-packages (13.3.4)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich[jupyter]) (2.14.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich[jupyter]) (2.2.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.5.1 in /usr/local/lib/python3.10/dist-packages (from rich[jupyter]) (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (5.5.6)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (3.6.4)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (3.0.7)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (7.34.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich[jupyter]) (0.1.2)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (6.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (6.1.12)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (4.4.2)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (3.0.38)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (4.8.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.18.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (67.7.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.2.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (6.4.8)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.8.3)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (23.2.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (5.3.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.17.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (21.3.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (5.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (3.1.2)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.8.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.5.6)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.16.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (6.5.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.2.6)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (2.1.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (6.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (4.11.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.7.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (23.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (4.9.2)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.2.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.5.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.2.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (4.3.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (23.1.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "aH-R4KaX3vEQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6nEben93JAk"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/Book3.csv',names=[\"text\",\"summary\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Suxgy7wC4IqL",
        "outputId": "8278634d-cd74-4c79-da52-15077388a2a2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0   I can't wait to see what happens next! Click ...   \n",
              "1   \"Seaside Shoreline,\" an x14\" Acrylic on Canva...   \n",
              "2   An ice-cold glass of guava lemonade is the pe...   \n",
              "3   Thinking about summer? We sure are Check out ...   \n",
              "4   A great design that you need to add to the li...   \n",
              "\n",
              "                                             summary  \n",
              "0  bit.ly/2Vn3q3The author is excited to see what...  \n",
              "1  A painting titled \"Seaside Shoreline\" measurin...  \n",
              "2   is the perfect summer drink!Guava Lemonade is...  \n",
              "3  bit.ly/2XzKHJWe are already looking forward to...  \n",
              "4  Before travelling to Istanbul, it is recommend...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcc7b6c8-02d6-4b76-8313-e87a1916f028\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I can't wait to see what happens next! Click ...</td>\n",
              "      <td>bit.ly/2Vn3q3The author is excited to see what...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Seaside Shoreline,\" an x14\" Acrylic on Canva...</td>\n",
              "      <td>A painting titled \"Seaside Shoreline\" measurin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>An ice-cold glass of guava lemonade is the pe...</td>\n",
              "      <td>is the perfect summer drink!Guava Lemonade is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thinking about summer? We sure are Check out ...</td>\n",
              "      <td>bit.ly/2XzKHJWe are already looking forward to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A great design that you need to add to the li...</td>\n",
              "      <td>Before travelling to Istanbul, it is recommend...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcc7b6c8-02d6-4b76-8313-e87a1916f028')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcc7b6c8-02d6-4b76-8313-e87a1916f028 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcc7b6c8-02d6-4b76-8313-e87a1916f028');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYfBicZQ59Jf"
      },
      "source": [
        "df[\"text\"] = \"summarize: \"+df[\"text\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81f4PKa1F6aM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "73bd5e89-72e9-4056-8b80-3cda2a848170"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  summarize:  I can't wait to see what happens n...   \n",
              "1  summarize:  \"Seaside Shoreline,\" an x14\" Acryl...   \n",
              "2  summarize:  An ice-cold glass of guava lemonad...   \n",
              "3  summarize:  Thinking about summer? We sure are...   \n",
              "4  summarize:  A great design that you need to ad...   \n",
              "\n",
              "                                             summary  \n",
              "0  bit.ly/2Vn3q3The author is excited to see what...  \n",
              "1  A painting titled \"Seaside Shoreline\" measurin...  \n",
              "2   is the perfect summer drink!Guava Lemonade is...  \n",
              "3  bit.ly/2XzKHJWe are already looking forward to...  \n",
              "4  Before travelling to Istanbul, it is recommend...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1040a0bb-0afa-4b4a-a6b9-950a8a871750\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>summarize:  I can't wait to see what happens n...</td>\n",
              "      <td>bit.ly/2Vn3q3The author is excited to see what...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>summarize:  \"Seaside Shoreline,\" an x14\" Acryl...</td>\n",
              "      <td>A painting titled \"Seaside Shoreline\" measurin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>summarize:  An ice-cold glass of guava lemonad...</td>\n",
              "      <td>is the perfect summer drink!Guava Lemonade is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>summarize:  Thinking about summer? We sure are...</td>\n",
              "      <td>bit.ly/2XzKHJWe are already looking forward to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>summarize:  A great design that you need to ad...</td>\n",
              "      <td>Before travelling to Istanbul, it is recommend...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1040a0bb-0afa-4b4a-a6b9-950a8a871750')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1040a0bb-0afa-4b4a-a6b9-950a8a871750 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1040a0bb-0afa-4b4a-a6b9-950a8a871750');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB441x104K-o"
      },
      "source": [
        "# Importing libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import os\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "from rich.table import Column, Table \n",
        "#Rich library in Python module\n",
        "# provides classes and functions for working with tables in console output.\n",
        "from rich import box\n",
        "from rich.console import Console\n",
        "#The rich.console module provides a way to create a console\n",
        "#object that can be used to display rich text and other output in the terminal.\n",
        "# define a rich console logger\n",
        "console=Console(record=True)\n",
        "\n",
        "def display_df(df):\n",
        "  \"\"\"display dataframe in ASCII format\"\"\"\n",
        "\n",
        "  console=Console()\n",
        "  table = Table(Column(\"source_text\", justify=\"center\" ), Column(\"target_text\", justify=\"center\"), title=\"Sample Data\",pad_edge=False, box=box.ASCII)\n",
        "\n",
        "  for i, row in enumerate(df.values.tolist()):\n",
        "    table.add_row(row[0], row[1])\n",
        "\n",
        "  console.print(table)\n",
        "\n",
        "training_logger = Table(Column(\"Epoch\", justify=\"center\" ), \n",
        "                        Column(\"Steps\", justify=\"center\"),\n",
        "                        Column(\"Loss\", justify=\"center\"), \n",
        "                        title=\"Training Status\",pad_edge=False, box=box.ASCII)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlYaKW9h4ai_"
      },
      "source": [
        "# Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Token and attention mask is generated for dataset:`**"
      ],
      "metadata": {
        "id": "e1nuxguJ7MFk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vLQPGAn4v17"
      },
      "source": [
        "class YourDataSetClass(Dataset):\n",
        "  \"\"\"\n",
        "  Creating a custom dataset for reading the dataset and \n",
        "  loading it into the dataloader to pass it to the neural network for finetuning the model\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, dataframe, tokenizer, source_len, target_len, source_text, target_text):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = dataframe\n",
        "    self.source_len = source_len\n",
        "    self.summ_len = target_len\n",
        "    self.target_text = self.data[target_text]\n",
        "    self.source_text = self.data[source_text]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.target_text)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    source_text = str(self.source_text[index])\n",
        "    target_text = str(self.target_text[index])\n",
        "\n",
        "    #cleaning data so as to ensure data is in string type\n",
        "    source_text = ' '.join(source_text.split())\n",
        "    target_text = ' '.join(target_text.split())\n",
        "\n",
        "    source = self.tokenizer.batch_encode_plus([source_text], max_length= self.source_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
        "    target = self.tokenizer.batch_encode_plus([target_text], max_length= self.summ_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
        "\n",
        "    #the batch_encode_plus method of the tokenizer object is called twice with source_text and target_text as input arguments. \n",
        "    #This method tokenizes the input text and returns a dictionary containing the input IDs and attention masks.\n",
        "\n",
        "    source_ids = source['input_ids'].squeeze()\n",
        "    source_mask = source['attention_mask'].squeeze()\n",
        "    target_ids = target['input_ids'].squeeze()\n",
        "    target_mask = target['attention_mask'].squeeze()\n",
        "    #squeeze() method to remove any unnecessary dimensions.\n",
        "\n",
        "    return {\n",
        "        'source_ids': source_ids.to(dtype=torch.long), \n",
        "        'source_mask': source_mask.to(dtype=torch.long), \n",
        "        'target_ids': target_ids.to(dtype=torch.long),\n",
        "        \n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkj6wIMt40RK"
      },
      "source": [
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to be called for training with the parameters passed from main function\n",
        "\n",
        "  \"\"\"\n",
        "  #loader: A PyTorch DataLoader object that loads training data in batches\n",
        "\n",
        "  model.train()\n",
        "  #setting the model to training mode\n",
        "  for _,data in enumerate(loader, 0):\n",
        "\n",
        "    y = data['target_ids'].to(device, dtype = torch.long)\n",
        "    y_ids = y[:, :-1].contiguous()\n",
        "    #selects all col except the last one,as it is used as EOS.\n",
        "\n",
        "    # Some operations in PyTorch, such as certain slicing and indexing operations, \n",
        "    # require the tensor to be contiguous in order to work properly. \n",
        "    # In such cases, calling contiguous() on the tensor ensures that the\n",
        "    #  tensor's' memory is laid out in a contiguous fashion,\n",
        "    #   so that the operation can be performed efficiently.\n",
        "\n",
        "\n",
        "    lm_labels = y[:, 1:].clone().detach()\n",
        "    #select all col except the first one,\n",
        "\n",
        "    #clone().detach() ensures that lm_labels is a new tensor\n",
        "    # that is not connected to the computation graph. \n",
        "    #This prevents any gradients from being computed for this tensor during backpropagation\n",
        "    # and avoids unnecessary memory usage.\n",
        "    lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "\n",
        "    \n",
        "    ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "    mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "    outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "    loss = outputs[0]\n",
        "\n",
        "    if _%10==0:\n",
        "      training_logger.add_row(str(epoch), str(_), str(loss))\n",
        "      console.print(training_logger)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**lm_labels:**The purpose of creating lm_labels is to set up the loss calculation for training the model. The transformer-based language model learns to predict the next token in the target sequence given the previous tokens. During training, the model is fed the input sequence and is trained to predict the target sequence tokens one by one. The model's predictions are compared against the actual target tokens to compute the loss, which is used to update the model parameters during backpropagation.\n",
        "\n",
        "To set up the loss calculation, we need to create a tensor that represents the target tokens for each predicted token in the sequence. We do this by shifting the y tensor one position to the right (y[:, 1:]) to get the \"actual\" next token for each input token. We then assign this shifted tensor to lm_labels.\n",
        "\n",
        "**outputs:**The outputs tensor is obtained by passing the input sequence (ids) and the attention mask (mask) to the encoder, and the y_ids tensor (which contains the target sequence with the last token removed) to the decoder. The labels argument specifies the \"actual\" next tokens for each predicted token in the sequence (i.e., lm_labels).\n",
        "\n",
        "**optimizer.zero.grad:**After logging the current batch's loss, the optimizer.zero_grad() statement is called to reset the gradients of all model parameters to zero. This is necessary because PyTorch accumulates gradients across batches by default, so we need to explicitly clear them after each batch.\n",
        "\n",
        "**loss.backward() and optimizer.step()**:The loss.backward() statement computes the gradients of the loss with respect to all model parameters using automatic differentiation. This allows us to compute the gradients efficiently without having to manually derive and implement the backpropagation algorithm.\n",
        "\n",
        "Finally, the optimizer.step() statement updates the model parameters using the computed gradients and the optimizer's update rule (e.g., SGD, Adam, etc.). This step is what actually causes the model to learn from the training data, by adjusting the parameters to minimize the loss.\n",
        "\n"
      ],
      "metadata": {
        "id": "b0sjfF6HO8lM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUBykK-A43DF"
      },
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to evaluate model for predictions\n",
        "\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  actuals = []\n",
        "  with torch.no_grad():\n",
        "      for _, data in enumerate(loader, 0):\n",
        "          y = data['target_ids'].to(device, dtype = torch.long)\n",
        "          ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "          mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "          generated_ids = model.generate(\n",
        "              input_ids = ids,\n",
        "              attention_mask = mask, \n",
        "              max_length=150, \n",
        "              num_beams=2,\n",
        "              repetition_penalty=2.5, \n",
        "              length_penalty=1.0, \n",
        "              early_stopping=True\n",
        "              )\n",
        "          preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "          target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "          if _%10==0:\n",
        "              console.print(f'Completed {_}')\n",
        "\n",
        "          predictions.extend(preds)\n",
        "          actuals.extend(target)\n",
        "  return predictions, actuals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model.generate:**\n",
        "**input_ids:** A tensor containing the token IDs of the input sequences.\n",
        "attention_mask: A tensor indicating which tokens should be attended to (1) and which tokens should not be attended to (0).\n",
        "\n",
        "**max_length:** An integer indicating the maximum length of the generated sequences.\n",
        "\n",
        "**num_beams:** An integer indicating the number of beams to use in beam search decoding. A higher number of beams may result in better quality predictions, but will also increase the computation time.\n",
        "\n",
        "**repetition_penalty:** A float value controlling the degree to which repeated tokens are penalized in the generation process. A higher value will result in fewer repeated tokens in the generated sequences.\n",
        "\n",
        "**length_penalty:** A float value controlling the degree to which shorter sequences are favored in the generation process. A higher value will result in shorter sequences.\n",
        "\n",
        "**early_stopping:** A boolean indicating whether to stop generation early when all beam hypotheses have reached the EOS token. This can be useful to avoid generating overly long sequences.\n",
        "\n",
        "**What is Beam?**\n",
        "In natural language processing, beam search is a decoding algorithm used in sequence-to-sequence models such as neural machine translation and text generation. Beam search generates multiple candidate output sequences, known as beams, and scores them using a scoring function. The scoring function takes into account the probability of each word in the sequence given the previous words generated so far, as well as other factors such as length normalization and repetition penalties.\n",
        "\n",
        "During generation, beam search maintains a set of k partial hypotheses, or \"beams\", where k is the beam width or the number of beams. At each time step, the model generates the probability distribution over the next token given the input sequence and the previously generated tokens. The k most likely partial hypotheses are then expanded by appending each possible next token to each of them, resulting in k * vocabulary_size new partial hypotheses. These new hypotheses are then pruned based on their scores and only the k most likely ones are retained for the next time step."
      ],
      "metadata": {
        "id": "7U412HPUrhin"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw4RW_qO4_8T"
      },
      "source": [
        "def T5Trainer(dataframe, source_text, target_text, model_params, output_dir=\"./outputs/\" ):\n",
        "  \n",
        "  \"\"\"\n",
        "  T5 trainer\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Set random seeds and deterministic pytorch for reproducibility\n",
        "  #  By setting the same seed for each run, we can ensure that the order of the data samples \n",
        "  #  is the same, and therefore the resulting weights and biases are also the same. \n",
        "  torch.manual_seed(model_params[\"SEED\"]) # pytorch random seed\n",
        "  np.random.seed(model_params[\"SEED\"]) # numpy random seed\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  # logging\n",
        "  console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
        "\n",
        "  # tokenzier for encoding the text\n",
        "  tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
        "\n",
        "  # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "  # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "  model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
        "  model = model.to(device)\n",
        "  \n",
        "  # logging\n",
        "  console.log(f\"[Data]: Reading data...\\n\")\n",
        "\n",
        "  # Importing the raw dataset\n",
        "  dataframe = dataframe[[source_text,target_text]]\n",
        "  display_df(dataframe.head(2))\n",
        "\n",
        "  \n",
        "  # Creation of Dataset and Dataloader\n",
        "  # Defining the train size. So 80% of the data will be used for training and the rest for validation. \n",
        "  train_size = 0.8\n",
        "  train_dataset=dataframe.sample(frac=train_size,random_state = model_params[\"SEED\"])\n",
        "  val_dataset=dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
        "  train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "  console.print(f\"FULL Dataset: {dataframe.shape}\")\n",
        "  console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
        "  console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n",
        "\n",
        "\n",
        "  # Creating the Training and Validation dataset for further creation of Dataloader\n",
        "  training_set = YourDataSetClass(train_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
        "  val_set = YourDataSetClass(val_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
        "\n",
        "\n",
        "  # Defining the parameters for creation of dataloaders\n",
        "  train_params = {\n",
        "      'batch_size': model_params[\"TRAIN_BATCH_SIZE\"],\n",
        "      'shuffle': True,\n",
        "      'num_workers': 0\n",
        "      }\n",
        "\n",
        "\n",
        "  val_params = {\n",
        "      'batch_size': model_params[\"VALID_BATCH_SIZE\"],\n",
        "      'shuffle': False,\n",
        "      'num_workers': 0\n",
        "      }\n",
        "\n",
        "\n",
        "  # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "  training_loader = DataLoader(training_set, **train_params)\n",
        "  val_loader = DataLoader(val_set, **val_params)\n",
        "\n",
        "\n",
        "  # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "  optimizer = torch.optim.Adam(params =  model.parameters(), lr=model_params[\"LEARNING_RATE\"])\n",
        "\n",
        "\n",
        "  # Training loop\n",
        "  console.log(f'[Initiating Fine Tuning]...\\n')\n",
        "\n",
        "  for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
        "      train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
        "      \n",
        "  \n",
        "  console.log(f\"[Saving Model]...\\n\")\n",
        "  #Saving the model after training\n",
        "  path = os.path.join(output_dir, \"model_files\")\n",
        "  model.save_pretrained(path)\n",
        "  tokenizer.save_pretrained(path)\n",
        "\n",
        "\n",
        "  # evaluating test dataset\n",
        "  console.log(f\"[Initiating Validation]...\\n\")\n",
        "  for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
        "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "    final_df.to_csv(os.path.join(output_dir,'predictions.csv'))\n",
        "  \n",
        "\n",
        "  \n",
        "  console.log(f\"[Validation Completed.]\\n\")\n",
        "  console.print(f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\")\n",
        "  console.print(f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\")\n",
        " \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxCpQwD8PDIs"
      },
      "source": [
        "model_params={\n",
        "    \"MODEL\":\"t5-base\",             # model_type: t5-base/t5-large\n",
        "    \"TRAIN_BATCH_SIZE\":8,          # training batch size\n",
        "    \"VALID_BATCH_SIZE\":8,          # validation batch size\n",
        "    \"TRAIN_EPOCHS\":3,              # number of training epochs\n",
        "    \"VAL_EPOCHS\":1,                # number of validation epochs\n",
        "    \"LEARNING_RATE\":1e-4,          # learning rate\n",
        "    \"MAX_SOURCE_TEXT_LENGTH\":512,  # max length of source text\n",
        "    \"MAX_TARGET_TEXT_LENGTH\":50,   # max length of target text\n",
        "    \"SEED\": 42                     # set seed for reproducibility \n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qijZoYeI55fM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0c925d4-6353-4e31-f5ca-d384c03c5ee7"
      },
      "source": [
        "T5Trainer(dataframe=df[:1000], source_text=\"text\", target_text=\"summary\", model_params=model_params, output_dir=\"outputs\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[03:26:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading t5-base\u001b[33m...\u001b[0m                                           \u001b[2m<ipython-input-34-1b21e750966f>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m14\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                                      \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:26:08] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading t5-base<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-34-1b21e750966f&gt;:14</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[03:26:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m                                               \u001b[2m<ipython-input-34-1b21e750966f>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m25\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                                      \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:26:12] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-34-1b21e750966f&gt;:25</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                                    Sample Data                                                    \u001b[0m\n",
              "+-----------------------------------------------------------------------------------------------------------------+\n",
              "|\u001b[1m                      source_text                      \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                      target_text                      \u001b[0m|\n",
              "|--------------------------------------------------------+--------------------------------------------------------|\n",
              "|  summarize:  I can't wait to see what happens next!    |   bit.ly/2Vn3q3The author is excited to see what will  |\n",
              "|    Click the link below and join my struggle! ://      |   happen next and is inviting others to join them in   |\n",
              "|                                                        |      their struggle by clicking the provided link.     |\n",
              "|  summarize:  \"Seaside Shoreline,\" an x14\" Acrylic on   |   A painting titled \"Seaside Shoreline\" measuring 14   |\n",
              "|               Canvas from June SOLD!!!                 |  inches in size, made with acrylic on canvas, was sold |\n",
              "|                                                        |                        in June.                        |\n",
              "+-----------------------------------------------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                    Sample Data                                                    </span>\n",
              "+-----------------------------------------------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">                      source_text                       </span>|<span style=\"font-weight: bold\">                       target_text                      </span>|\n",
              "|--------------------------------------------------------+--------------------------------------------------------|\n",
              "|  summarize:  I can't wait to see what happens next!    |   bit.ly/2Vn3q3The author is excited to see what will  |\n",
              "|    Click the link below and join my struggle! ://      |   happen next and is inviting others to join them in   |\n",
              "|                                                        |      their struggle by clicking the provided link.     |\n",
              "|  summarize:  \"Seaside Shoreline,\" an x14\" Acrylic on   |   A painting titled \"Seaside Shoreline\" measuring 14   |\n",
              "|               Canvas from June SOLD!!!                 |  inches in size, made with acrylic on canvas, was sold |\n",
              "|                                                        |                        in June.                        |\n",
              "+-----------------------------------------------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FULL Dataset: \u001b[1m(\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TRAIN Dataset: \u001b[1m(\u001b[0m\u001b[1;36m800\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TEST Dataset: \u001b[1m(\u001b[0m\u001b[1;36m200\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEST Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                           \u001b[2m<ipython-input-34-1b21e750966f>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m74\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                                      \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-34-1b21e750966f&gt;:74</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  40   | tensor(1.4067, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  40   | tensor(1.4067, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  40   | tensor(1.4067, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  50   | tensor(1.4058, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  40   | tensor(1.4067, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  50   | tensor(1.4058, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  40   | tensor(1.4067, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  50   | tensor(1.4058, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  60   | tensor(1.9142, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  40   | tensor(1.4067, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  50   | tensor(1.4058, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  60   | tensor(1.9142, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  40   | tensor(1.4067, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  50   | tensor(1.4058, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  60   | tensor(1.9142, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  70   | tensor(2.0133, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  40   | tensor(1.4067, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  50   | tensor(1.4058, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  60   | tensor(1.9142, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  70   | tensor(2.0133, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  40   | tensor(1.4067, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  50   | tensor(1.4058, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  60   | tensor(1.9142, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  70   | tensor(2.0133, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  80   | tensor(2.1857, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  40   | tensor(1.4067, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  50   | tensor(1.4058, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  60   | tensor(1.9142, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  70   | tensor(2.0133, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  80   | tensor(2.1857, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                               Training Status                               \u001b[0m\n",
              "+---------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  40   | tensor(1.4067, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  50   | tensor(1.4058, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  60   | tensor(1.9142, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  70   | tensor(2.0133, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  80   | tensor(2.1857, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "|  2   |  90   | tensor(1.4875, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
              "+---------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
              "+---------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
              "|------+-------+------------------------------------------------------------|\n",
              "|  0   |   0   | tensor(7.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  10   | tensor(3.6275, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  20   | tensor(3.4530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  30   | tensor(2.7804, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  40   | tensor(2.3730, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  50   | tensor(2.4802, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  60   | tensor(2.4980, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  70   | tensor(3.0783, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  80   | tensor(2.2063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  0   |  90   | tensor(2.8969, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |   0   | tensor(1.9756, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  10   | tensor(2.0191, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  20   | tensor(2.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  30   | tensor(2.4339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  40   | tensor(2.1603, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  50   | tensor(1.8071, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  60   | tensor(1.5884, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  70   | tensor(2.0320, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  80   | tensor(2.6018, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  1   |  90   | tensor(1.8637, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |   0   | tensor(1.4372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  10   | tensor(1.7295, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  20   | tensor(1.5762, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  30   | tensor(2.1875, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  40   | tensor(1.4067, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  50   | tensor(1.4058, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  60   | tensor(1.9142, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  70   | tensor(2.0133, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  80   | tensor(2.1857, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "|  2   |  90   | tensor(1.4875, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
              "+---------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[03:31:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mSaving Model\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                     \u001b[2m<ipython-input-34-1b21e750966f>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m80\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                                      \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:31:12] </span><span style=\"font-weight: bold\">[</span>Saving Model<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-34-1b21e750966f&gt;:80</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[03:31:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Validation\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                            \u001b[2m<ipython-input-34-1b21e750966f>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m88\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                                      \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:31:15] </span><span style=\"font-weight: bold\">[</span>Initiating Validation<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-34-1b21e750966f&gt;:88</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Completed \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Completed \u001b[1;36m10\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Completed \u001b[1;36m20\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[03:32:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mValidation Completed.\u001b[1m]\u001b[0m                                               \u001b[2m<ipython-input-34-1b21e750966f>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m96\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                                      \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:32:13] </span><span style=\"font-weight: bold\">[</span>Validation Completed.<span style=\"font-weight: bold\">]</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-34-1b21e750966f&gt;:96</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m Model saved @ outputs/model_files\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span> Model saved @ outputs/model_files\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mValidation\u001b[1m]\u001b[0m Generation on Validation data saved @ outputs/predictions.csv\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Validation<span style=\"font-weight: bold\">]</span> Generation on Validation data saved @ outputs/predictions.csv\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7SFz-6usqym"
      },
      "source": [
        "Prediction_df = pd.read_csv('/content/outputs/predictions.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Prediction_df "
      ],
      "metadata": {
        "id": "ZC8EuMDEFLj5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "5b819108-4c3f-4cd6-cc7b-82efdd8c2393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                     Generated Text  \\\n",
              "0             0  \"Seaside Shoreline,\" an x14\" acrylic on canvas...   \n",
              "1             1  A great design that you need to add to the lis...   \n",
              "2             2  Our photography competition is open! Categorie...   \n",
              "3             3  Jasmin Bhasin looks glamorous in green and pin...   \n",
              "4             4  the traditional system was always way too long...   \n",
              "..          ...                                                ...   \n",
              "195         195                          Important levels for Apr.   \n",
              "196         196  My realtor has sent me gift cards/nice notes s...   \n",
              "197         197  We use the worlds open monetary network to giv...   \n",
              "198         198  U.S. Employers added jobs in March: Live Updat...   \n",
              "199         199  We are under attack. First, the biowarfare and...   \n",
              "\n",
              "                                           Actual Text  \n",
              "0    A painting titled \"Seaside Shoreline\" measurin...  \n",
              "1    Before travelling to Istanbul, it is recommend...  \n",
              "2                                                  NaN  \n",
              "3    Jasmin Bhasin was spotted looking glamorous in...  \n",
              "4    This tweet suggests that traditional schooling...  \n",
              "..                                                 ...  \n",
              "195  -Jun quarterThe tweets are discussing the impo...  \n",
              "196  pandemic.Since the start of the pandemic, my r...  \n",
              "197  This tweet is about how the open monetary netw...  \n",
              "198  In March, US employers added jobs, according t...  \n",
              "199  The tweets suggest that people should not rely...  \n",
              "\n",
              "[200 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e66c9685-7b15-496f-9f5a-5c18b4286992\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Generated Text</th>\n",
              "      <th>Actual Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Seaside Shoreline,\" an x14\" acrylic on canvas...</td>\n",
              "      <td>A painting titled \"Seaside Shoreline\" measurin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A great design that you need to add to the lis...</td>\n",
              "      <td>Before travelling to Istanbul, it is recommend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Our photography competition is open! Categorie...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Jasmin Bhasin looks glamorous in green and pin...</td>\n",
              "      <td>Jasmin Bhasin was spotted looking glamorous in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>the traditional system was always way too long...</td>\n",
              "      <td>This tweet suggests that traditional schooling...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>195</td>\n",
              "      <td>Important levels for Apr.</td>\n",
              "      <td>-Jun quarterThe tweets are discussing the impo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>196</td>\n",
              "      <td>My realtor has sent me gift cards/nice notes s...</td>\n",
              "      <td>pandemic.Since the start of the pandemic, my r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>197</td>\n",
              "      <td>We use the worlds open monetary network to giv...</td>\n",
              "      <td>This tweet is about how the open monetary netw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>198</td>\n",
              "      <td>U.S. Employers added jobs in March: Live Updat...</td>\n",
              "      <td>In March, US employers added jobs, according t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>199</td>\n",
              "      <td>We are under attack. First, the biowarfare and...</td>\n",
              "      <td>The tweets suggest that people should not rely...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e66c9685-7b15-496f-9f5a-5c18b4286992')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e66c9685-7b15-496f-9f5a-5c18b4286992 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e66c9685-7b15-496f-9f5a-5c18b4286992');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Generated_text = Prediction_df[\"Generated Text\"]"
      ],
      "metadata": {
        "id": "5v3EiYFwFW-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Generated_text=Generated_text.values.tolist()"
      ],
      "metadata": {
        "id": "D5fLQpwOGNwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Actual_text = Prediction_df[\"Actual Text\"]"
      ],
      "metadata": {
        "id": "Tj7p1zI0GSbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Actual_text=Actual_text.values.tolist()"
      ],
      "metadata": {
        "id": "40ZGxX9kGyUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Generated_text = str(Generated_text)\n",
        "Actual_text = str(Actual_text)"
      ],
      "metadata": {
        "id": "ovhP0rZfRY_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge\n",
        "\n",
        "# predicted and actual texts for multiple rows\n",
        "# predicted_texts = ['this is a predicted text', 'this is another predicted text']\n",
        "# actual_texts = ['this is an actual text', 'this is another actual text']\n",
        "\n",
        "# initialize the ROUGE scorer\n",
        "rouge = Rouge()\n",
        "\n",
        "# compute the ROUGE scores for each row\n",
        "scores = rouge.get_scores(Generated_text, Actual_text, avg=True)\n",
        "\n",
        "# print the average scores\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "Aw6YkuRtGzSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54bde6c6-cbb5-4501-85cc-dead89870966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "{'rouge-1': {'r': 0.4482081492390771, 'p': 0.5178672716959728, 'f': 0.48052631081546954}, 'rouge-2': {'r': 0.20324629498941427, 'p': 0.2638973732437385, 'f': 0.2296345465793009}, 'rouge-l': {'r': 0.41580756013745707, 'p': 0.48043108338060125, 'f': 0.44578946871020647}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0H0vR9Z-eOnp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}